# Applications d'IA pour la vision et l'audio

Dans cette le√ßon, d√©couvrez comment l'IA de vision permet √† vos applications de g√©n√©rer et d'interpr√©ter des images. L'IA audio permet √† vos applications de g√©n√©rer de l'audio et m√™me de le transcrire en temps r√©el.

---

## Vision

[![Explication sur l'IA de vision](https://img.youtube.com/vi/QXbASt1KXuw/0.jpg)](https://youtu.be/QXbASt1KXuw?feature=shared)

_‚¨ÜÔ∏èCliquez sur l'image pour regarder la vid√©o‚¨ÜÔ∏è_

Les approches bas√©es sur l'IA de vision sont utilis√©es pour g√©n√©rer et interpr√©ter des images. Cela peut √™tre utile pour un large √©ventail d'applications, telles que la reconnaissance d'images, la g√©n√©ration d'images et la manipulation d'images. Les mod√®les actuels sont multimodaux, ce qui signifie qu'ils peuvent accepter une vari√©t√© d'entr√©es, comme du texte, des images et de l'audio, et g√©n√©rer une vari√©t√© de sorties. Dans ce cas, nous allons nous concentrer sur la reconnaissance d'images.

### Reconnaissance d'images avec MEAI

La reconnaissance d'images va au-del√† de demander au mod√®le d'IA ce qu'il pense √™tre pr√©sent dans une image. Vous pouvez √©galement poser des questions sur l'image, par exemple : _Combien de personnes sont pr√©sentes et pleut-il ?_

Tr√®s bien - nous allons mettre le mod√®le √† l'√©preuve et lui demander s'il peut nous dire combien de chaussures rouges se trouvent sur la premi√®re photo, puis lui faire analyser un re√ßu en allemand pour savoir combien laisser comme pourboire.

![Un montage montrant les deux images utilis√©es dans l'exemple. La premi√®re montre plusieurs coureurs, mais uniquement leurs jambes. La seconde est un re√ßu de restaurant allemand](../../../translated_images/example-visual-image.e2fc4ffa5f01b3d65bb9bd5d23eebf97513bf486b761209b28fea06b63a11f6c.fr.png)

> üßë‚Äçüíª**Code d'exemple** : Vous pouvez suivre [le code d'exemple ici](../../../03-CoreGenerativeAITechniques/src/Vision-01MEAI-GitHubModels).

1. Nous utilisons MEAI et les mod√®les GitHub, donc instanciez le `IChatClient` comme nous l'avons fait jusqu'√† pr√©sent. Commencez √©galement √† cr√©er un historique de conversation.

    ```csharp
    IChatClient chatClient = new ChatCompletionsClient(
        endpoint: new Uri("https://models.inference.ai.azure.com"),
        new AzureKeyCredential(githubToken)) // make sure to grab githubToken from the secrets or environment
    .AsChatClient("gpt-4o-mini");

    List<ChatMessage> messages = 
    [
        new ChatMessage(ChatRole.System, "You are a useful assistant that describes images using a direct style."),
        new ChatMessage(ChatRole.User, "How many red shoes are in the photo?") // we'll start with the running photo
    ];
    ```

1. La prochaine √©tape consiste √† charger l'image dans un objet `AIContent`, √† l'int√©grer √† notre conversation, puis √† l'envoyer au mod√®le pour qu'il la d√©crive pour nous.

    ```csharp
    var imagePath = "FULL PATH TO THE IMAGE ON DISK";

    AIContent imageContent = new DataContent(File.ReadAllBytes(imagePath), "image/jpeg"); // the important part here is that we're loading it in bytes. The image could come from anywhere.

    var imageMessage = new ChatMessage(ChatRole.User, [imageContent]);

    messages.Add(imageMessage);

    var response = await chatClient.GetResponseAsync(messages);

    messages.Add(response.Message);

    Console.WriteLine(response.Message.Text);
    ```

1. Ensuite, pour demander au mod√®le de travailler sur le re√ßu de restaurant - qui est en allemand - afin de d√©terminer combien de pourboire nous devrions laisser :

    ```csharp
    // this will go after the previous code block
    messages.Add(new ChatMessage(ChatRole.User, "This is a receipt from a lunch. I had the sausage. How much of a tip should I leave?"));

    var receiptPath = "FULL PATH TO THE RECEIPT IMAGE ON DISK";

    AIContent receiptContent = new DataContent(File.ReadAllBytes(receiptPath), "image/jpeg");
    var receiptMessage = new ChatMessage(ChatRole.User, [receiptContent]);

    messages.Add(receiptMessage);

    response = await chatClient.GetResponseAsync(messages);
    messages.Add(response.Message);

    Console.WriteLine(response.Message.Text);
    ```

Voici un point que je souhaite souligner. Nous dialoguons avec un mod√®le linguistique, ou plus pr√©cis√©ment un mod√®le multimodal capable de g√©rer des interactions textuelles ainsi que des interactions avec des images (et de l'audio). Et nous poursuivons la conversation avec le mod√®le comme d'habitude. Bien s√ªr, c'est un type d'objet diff√©rent que nous envoyons au mod√®le, `AIContent` instead of a `string`, but the workflow is the same.

> üôã **Need help?**: If you encounter any issues, [open an issue in the repository](https://github.com/microsoft/Generative-AI-for-beginners-dotnet/issues/new).

## Audio AI

[![Audio AI explainer video](https://img.youtube.com/vi/fuquPXRNqCo/0.jpg)](https://youtu.be/fuquPXRNqCo?feature=shared)

_‚¨ÜÔ∏èClick the image to watch the video‚¨ÜÔ∏è_

Real-time audio techniques allow your apps to generate audio and transcribe it in real-time. This can be useful for a wide range of applications, such as voice recognition, speech synthesis, and audio manipulation.

But we're going to have to transition away from MEAI and from the model we were using to Azure AI Speech Services.

To setup an Azure AI Speech Service model, [follow these directions](../02-SetupDevEnvironment/getting-started-azure-openai.md) but instead of choosing an OpenAI model, choose **Azure-AI-Speech**.

> **üóíÔ∏èNote:>** Audio is coming to MEAI, but as of this writing isn't available yet. When it is available we'll update this course.

### Implementing speech-to-text with Cognitive Services

You'll need the **Microsoft.CognitiveServices.Speech** NuGet package for this example.

> üßë‚Äçüíª**Sample code**: You can follow [along with sample code here](../../../03-CoreGenerativeAITechniques/src/Audio-01-SpeechMic).

1. The first thing we'll do (after grabbing the key and region of the model's deployment) is instantiate a `SpeechTranslationConfig`. Cela nous permet d'indiquer au mod√®le que nous allons utiliser de l'anglais parl√© et le traduire en espagnol √©crit.

    ```csharp
    var speechKey = "<FROM YOUR MODEL DEPLOYMENT>";
    var speechRegion = "<FROM YOUR MODEL DEPLOYMENT>";

    var speechTranslationConfig = SpeechTranslationConfig.FromSubscription(speechKey, speechRegion);
    speechTranslationConfig.SpeechRecognitionLanguage = "en-US";
    speechTranslationConfig.AddTargetLanguage("es-ES");
    ```

1. Ensuite, nous devons obtenir l'acc√®s au microphone et cr√©er un nouvel objet `TranslationRecognizer` qui communiquera avec le mod√®le.

    ```csharp
    using var audioConfig = AudioConfig.FromDefaultMicrophoneInput();
    using var translationRecognizer = new TranslationRecognizer(speechTranslationConfig, audioConfig);
    ```

1. Enfin, nous appellerons le mod√®le et configurerons une fonction pour g√©rer son retour.

    ```csharp
    var translationRecognitionResult = await translationRecognizer.RecognizeOnceAsync();
    OutputSpeechRecognitionResult(translationRecognitionResult);

    void OutputSpeechRecognitionResult(TranslationRecognitionResult translationRecognitionResult)
    {
        switch (translationRecognitionResult.Reason)
        {
            case ResultReason.TranslatedSpeech:
                Console.WriteLine($"RECOGNIZED: Text={translationRecognitionResult.Text}");
                foreach (var element in translationRecognitionResult.Translations)
                {
                    Console.WriteLine($"TRANSLATED into '{element.Key}': {element.Value}");
                }
                break;
            case ResultReason.NoMatch:
                // handle when speech could not be recognized
                break;
            case ResultReason.Canceled:
                // handle an error condition
                break;
        }
    }
    ```

L'utilisation de l'IA pour traiter de l'audio est un peu diff√©rente de ce que nous avons fait jusqu'√† pr√©sent, car nous utilisons les services Azure AI Speech pour ce faire, mais les r√©sultats de la traduction de l'audio parl√© en texte sont assez impressionnants.

> üôã **Besoin d'aide ?** : Si vous rencontrez des probl√®mes, [ouvrez une issue dans le d√©p√¥t](https://github.com/microsoft/Generative-AI-for-beginners-dotnet/issues/new).

Nous avons un autre exemple qui [d√©montre comment r√©aliser une conversation audio en temps r√©el avec Azure Open AI](../../../03-CoreGenerativeAITechniques/src/Audio-02-RealTimeAudio) - allez y jeter un ≈ìil !

## Ressources suppl√©mentaires

- [G√©n√©rer des images avec l'IA et .NET](https://learn.microsoft.com/dotnet/ai/quickstarts/quickstart-openai-generate-images?tabs=azd&pivots=openai)

## Et ensuite

Vous avez appris comment ajouter des capacit√©s de vision et d'audio √† vos applications .NET. Dans la prochaine le√ßon, d√©couvrez comment cr√©er une IA capable d'agir de mani√®re autonome.

üëâ [D√©couvrez les agents IA](./04-agents.md).

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide de services de traduction automatis√©e bas√©s sur l'intelligence artificielle. Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatiques peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de faire appel √† une traduction professionnelle humaine. Nous d√©clinons toute responsabilit√© en cas de malentendus ou d'interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.